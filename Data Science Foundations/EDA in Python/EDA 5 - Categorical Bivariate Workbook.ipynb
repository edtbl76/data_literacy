{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0308b580-681b-439d-94e2-f459f8ee1135",
   "metadata": {},
   "source": [
    "# EDA 5 - Categorical Bivariate Analysis\n",
    "In EDA 4, we did a bivariate analysis that compared two quantitative variables. Now we're going to focus on two categorical variables. \n",
    "\n",
    "There was a LOT of math in the last lesson. This should be a bit easier because our sample (hint, not a population!) is from the NPI-40, which is the Narcissistic Personality Inventory. This is a personality test w/ 40 questions. Each of the questions are yes/no, so all of the variables are binary. \n",
    "\n",
    "We're going to look at just a subset of the 40 questions: \n",
    "- **influence**: *yes* = I have a natural talent for influencing people; *no* = I am not good at influencing people.\n",
    "- **blend_in**: *yes* = I prefer to blend in with the crowd; *no* = I like to be the center of attention.\n",
    "- **special**: *yes* = I think I am a special person; *no* = I am no better or worse than most people.\n",
    "- **leader**: *yes* = I see myself as a good leader; *no* = I am not sure if I would make a good leader.\n",
    "- **authority**: *yes* = I like to have authority over other people; *no* = I don’t mind following orders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fa0f7f-20c8-40df-9b7e-fc5f2b6016c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "npi40 = pd.read_csv('npi_40.csv')\n",
    "npi40.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb420c6b-6d41-43d1-85a4-278d96894a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# info\n",
    "npi40.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3894c61d-fda4-439c-96bf-c4508e15dcd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarization\n",
    "## NOTE: Since we only have categorical variables, we don't need to specify include='all'\n",
    "npi40.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e7feea-ac14-4908-9639-c0b3c756a35f",
   "metadata": {},
   "source": [
    "---\n",
    "Before we get to the meat and potatoes, let's look at the data and think about what might be associated? (Silently, that means me too.. I'm not going to write the notes here.) \n",
    "\n",
    "### Contingency Tables (Frequencies) \n",
    "\n",
    "Contingency Tables (a.k.a Two-Way Tables, Cross-Tabulations, Crosstabs) are a useful tool for summarizing two variables at the same time. It's similar to ```value_counts()```. \n",
    "\n",
    "\n",
    "Let's look at two examples: \n",
    "- **leader** vs. **influence**\n",
    "- **special** vs **authority**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447d1731-ef5a-4573-8ed6-02a62f0067d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# crosstab for leader vs. influence\n",
    "leader_influence_ct = pd.crosstab(npi40.leader, npi40.influence)\n",
    "leader_influence_ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d12c723-d32f-422b-b945-4caa065340bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# crosstab for special  vs. authority\n",
    "special_authority_ct = pd.crosstab(npi40.special, npi40.authority)\n",
    "special_authority_ct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e98d85-2678-4bd8-b595-562de1fcc3ac",
   "metadata": {},
   "source": [
    "\n",
    "I'll use the first example to show you how to read these: \n",
    "- 3015 people have determined that they aren't influential or a leader\n",
    "- 2360 people have determined that they are influential but not a leader\n",
    "- 1293 people have determined that they aren't influential but they are a leader.\n",
    "- 4429 people have determined that they are both influential and a leader.\n",
    "\n",
    "How do we **assess an association?** We have to look at the responses and the magnitude of the commonality to determine if information about one variable gives us additional information about the other variable. \n",
    "\n",
    "Looking at the results above, the 4429 gives us the strongest indicator, that those who think they are a good leader, are also influential (or vice versa). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d53308-29f3-4251-9e18-1a5047b581c9",
   "metadata": {},
   "source": [
    "### Contingency Tables (Proporitions)\n",
    "\n",
    "You may have remembered some of the challenges with previous statistical analysis: raw values are often not good indicators for strength or magnitude, because they don't have broad significance beyond the single observation. As a result, we often calculate them as proportions. \n",
    "\n",
    "Let's go ahead and do that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395f057f-9b41-4914-b17f-6595bdcef4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# leaders and influence\n",
    "leader_influence_ct_prop = leader_influence_ct / len(npi40)\n",
    "leader_influence_ct_prop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1caaa52d-7ee6-4358-944e-bbf58b93a934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# special and authority\n",
    "special_authority_ct_prop = special_authority_ct / len(npi40)\n",
    "special_authority_ct_prop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f52dc03-5500-4f50-8044-b322495e6b7f",
   "metadata": {},
   "source": [
    "It quickly becomes clear how much easier this is to interpret. \n",
    "\n",
    "Almost 40% of the sample in the first case view themselves as both influential and good leaders, 27% view themselves in the inverse. \n",
    "\n",
    "Special and authority are a little bit less conclusive...\n",
    "\n",
    "### Marginal Proporition\n",
    "\n",
    "All else equal, we might expect that each quadrant reflects 1/4 (25% of the people) This would mean that respondents in any single category (top row, bottom row, left column, bottom column, diagonals) represents 50%. \n",
    "\n",
    "Well, this isn't accurate, but the concept of looking at respondents of single categories (and their sums) is the definition of **marginal proportions**. We can carry this out by summing the relevant values. \n",
    "\n",
    "To calculate the leadership **marginal proportions** sum the no rows and the yes rows to get the total no/yes proportions for leadership respectively\n",
    "- (no) 0.271695+0.212670 = **0.484365**\n",
    "- (yes) 0.116518+0.399117 = **0.515635**\n",
    "\n",
    "If we want to calculate the influence **marginal proportions**, you'd sum the no and yes columns. This can be done programmatically w/ ```sum()``` and manipulating the ```axis``` parameter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa97398-4b75-4731-9853-408fdc1b114f",
   "metadata": {},
   "outputs": [],
   "source": [
    "leader_marginal_proportions = leader_influence_ct_prop.sum(axis=1)\n",
    "leader_marginal_proportions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0686d0aa-19e4-494a-af16-a4e75442e9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "influence_marginal_proportions = leader_influence_ct_prop.sum(axis=0)\n",
    "influence_marginal_proportions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8141edd2-cabf-431b-af27-4a41a282d692",
   "metadata": {},
   "source": [
    "By investinging the marginal proportions, we've found that more people feel they have a talent for influence, but they are split on whether or not they are good leaders. \n",
    "\n",
    "### Expected Contingency Tables. \n",
    "\n",
    "This is a tool that help us better understand association between categorical variables. We use **marginal proporitions** to create a specical contingency table of *expected proportions* between the variables under the assumption that they have **no association**. \n",
    "\n",
    "We accomplish this by \n",
    "- calculating the product of each combination of categories.\n",
    "- we then de-normalize the data by multiplying the resulting proportions by the sample size to convert the proportions back into frequencies.\n",
    "\n",
    "Let's multiply the product of our **marginal proportions**:\n",
    "\n",
    "| | **influence = no** | **influence = yes** | \n",
    "|-|-|-|\n",
    "| **leader = no** | 0.484365×0.388213 = **0.18803679** | 0.484365×0.611787 = **0.29632821**  | \n",
    "| **leader = yes** | 0.515635×0.388213 = **0.20017621** | 0.515635×0.611787 = **0.31545879** | \n",
    "\n",
    "Now let's multiply each of these by the sample size of the dataset (11097) to de-normalize them back into frequencies. \n",
    "\n",
    "| | **influence = no** | **influence = yes** | \n",
    "|-|-|-|\n",
    "| **leader = no** | 0.18803679*11097 = **2086.64425863** | 0.29632821*11097 = **3288.35414637** | \n",
    "| **leader = yes** |  0.20017621*11097 = **2221.35540237** | 0.31545879*11097 = **3500.64619263** | \n",
    "\n",
    "Now, let's round off those values to whole numbers to arrive out our **expected contingency tables**\n",
    "\n",
    "| | **influence = no** | **influence = yes** | \n",
    "|-|-|-|\n",
    "| **leader = no** | 2087 | 3288 | \n",
    "| **leader = yes** | 2221 | 3501 | \n",
    "\n",
    "What this table tells us is that *if there were **no** association between the **leader** and **influence** questions* we would expect 2087 people to answer *no* to both and 3501 people to answer *yes* to both, and so on. \n",
    "\n",
    "---\n",
    "\n",
    "Cool right! That's a lot of math (less than the last lesson, though!) \n",
    "\n",
    "As usual, there is an easier way to do this with python libraries! (```numpy```, ```scipy.stats.chi2_contingency```). Let's check our work. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d890da79-b09a-4925-af7f-5e56ef2ec82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's import those libraries. \n",
    "import numpy as np\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# due to the magic of python and scipy.stats, we don't need to compute the marginal proportions, we just need the original observed contingency table\n",
    "## ignore the details of this command, we'll eventua\n",
    "ch2, pval, dof, expected = chi2_contingency(leader_influence_ct)\n",
    "\n",
    "expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549fba91-6339-4bb4-9978-ffd8ec3e24fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hmm. There must be a way to round this off easily.. didn't Ed say that we needed numpy? \n",
    "np.round(expected)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a840c4e-37c3-4d5b-a64c-2a514aea9bcc",
   "metadata": {},
   "source": [
    "The numbers look familiar!\n",
    "\n",
    "So let's compare these values to the original contingency table? \n",
    "\n",
    "| **observed** | **influence = no** | **influence = yes** | \n",
    "|-|-|-|\n",
    "| **leader = no** | 3015 | 2360 | \n",
    "| **leader = yes** | 1293 | 4429 | \n",
    "\n",
    "| **expected** | **influence = no** | **influence = yes** | \n",
    "|-|-|-|\n",
    "| **leader = no** | 2087 | 3288 | \n",
    "| **leader = yes** | 2221 | 3501 | \n",
    "\n",
    "The values we observed showed some strong differences between no/no and yes/yes. They were much higher than the expected table. Remember that the expected contingencies are expected under the condition of \"no association.\" You'll note that the no/yes and yes/no associations decrease. This is normal. If proportional relationships increase, then inverse proportional relationships decrease. (and vice versa). \n",
    "\n",
    "This can be hard for some to wrap their head around. We aren't changing the sample size. The expected contingencies attempt to establish a baseline for the values without any association, so that we can evaluate the magnitude of the delta between our observations and the baseline. We can't just look at a single quadrant, we have to look at the contingencies and/or proportions holistically in order to determine that there is an association between the variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4335cf5-b4c1-415b-8530-dd340b417d69",
   "metadata": {},
   "source": [
    "### Chi-Square Statistic\n",
    "\n",
    "After we compared the observed and expected values, we were able to determine that there is likely an association between the two. However, as we've discussed, frequencies aren't very good at establishing the magnitude or strength of the difference to help us use it as a tool for predictability about future study. Normally, we use proporitions, hwoever as I mentioned, we look at the tables holistically, which means that even the delta between observed and expected ends up being a scalar value, not a proportion. (the difference between two percentages or proporitions is expressed as a percentage only in terms of units, not as a proporition in statistical measure). \n",
    "\n",
    "Another way of stating this is that it's not a part of a single whole, but rather a gap between two separate proportions. \n",
    "\n",
    "So we use the **chi-square** statistic to summarize how different the two contingency tables are. The calculation is as follows: \n",
    "1. find the squared difference between each value in the observed table and it's corresponding value in the expected table\n",
    "2. divide the result(s) of step 1 by the value from the expected table\n",
    "3. Add those numbers up to get the result.\n",
    "\n",
    "*You: Ed, are you really going to make me do the math?\"\n",
    "*Me: Have you met me?*\n",
    "\n",
    "#### Step 1: Find the difference between the tables. \n",
    "Since we're going to square the results, the order of subtraction doesn't matter. That said, every version of this I've ever been taught have shown *observed - expected*, so I'm going to do the same. \n",
    "\n",
    "| **observed - expected** | **influence = no** | **influence = yes** | \n",
    "|-|-|-|\n",
    "| **leader = no** | 3015 - 2087 = **928** | 2360 - 3288 = **-928** | \n",
    "| **leader = yes** | 1293 - 2221 = **-928** | 4429 - 3501 = **928** | \n",
    "\n",
    "See why it doesn't matter now?\n",
    "\n",
    "| **squared** | **influence = no** | **influence = yes** | \n",
    "|-|-|-|\n",
    "| **leader = no** | 928^2 = **861184** | -928^2 = **861184** | \n",
    "| **leader = yes** | -928^2 = **861184** | 928^2 = **861184** | \n",
    "\n",
    "#### Step 2: Divide the results by their expected vable\n",
    "\n",
    "| **divided by expected** | **influence = no** | **influence = yes** | \n",
    "|-|-|-|\n",
    "| **leader = no** | 861184 / 2087 = **412.642069957** | 861184 / 3288 = **261.917274939** | \n",
    "| **leader = yes** | 861184 / 2221 = **387.746060333** | 861184 / 3501 = **245.982290774** | \n",
    "\n",
    "#### Step 3: Add 'em up!\n",
    "\n",
    "412.642069957 + 261.917274939 + 387.746060333 + 245.982290774 = **1308.287696003**\n",
    "\n",
    "Now let's calculate the result to check our math..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df8af64-19bc-4a11-b2d0-37d55bd9670e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ready to get really annoyed? You've already calculated the variable. It was part of the chi2_contingency output above. \n",
    "ch2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb94c08-1911-4105-9278-99882d4782f0",
   "metadata": {},
   "source": [
    "---\n",
    "You'll notice that the numbers are slightly different. Remember that we did a lot of rounding in this process. It's worth trusting the output of ```scipy.stats```. You **can** go back and do this all by hand and get the same result. \n",
    "\n",
    "I want to stop for a moment to emphasize why these libraries are so valuable to data scientists. This takes the complexity and **error-prone** nature of math by hand out of the science. \n",
    "\n",
    "---\n",
    "So how do we interpret the number? \n",
    "\n",
    "This gets a little complicated, and we're going to get more into this later, but the interpretation depends on the complexity of the table. \n",
    "\n",
    "We calculate a value called **degrees of freedom**, which is (num_of_rows - 1) * (num_of_cols - 1). For a 2 x 2 table, **df (degrees of freedom)** is 1. \n",
    "\n",
    "We also select a **significance level** (\\alpha). 0.05 is the most commonly used value. This value has to do with/ probability, and I'm going to handwave over it for now. (We'll get there, I promise!) \n",
    "\n",
    "#### Chi-Square Critical Values Table\n",
    "\n",
    "| Degrees of Freedom (df) | \\(\\alpha = 0.10\\) | \\(\\alpha = 0.05\\) | \\(\\alpha = 0.01\\) | \\(\\alpha = 0.001\\) |\n",
    "|-------------------------|-------------------|-------------------|-------------------|--------------------|\n",
    "| 1                       | 2.706             | 3.841             | 6.635             | 10.828             |\n",
    "| 2                       | 4.605             | 5.991             | 9.210             | 13.816             |\n",
    "| 3                       | 6.251             | 7.815             | 11.345            | 16.266             |\n",
    "| 4                       | 7.779             | 9.488             | 13.277            | 18.467             |\n",
    "| 5                       | 9.236             | 11.070            | 15.086            | 20.515             |\n",
    "| 6                       | 10.645            | 12.592            | 16.812            | 22.458             |\n",
    "| 7                       | 12.017            | 14.067            | 18.475            | 24.322             |\n",
    "| 8                       | 13.362            | 15.507            | 20.090            | 26.125             |\n",
    "| 9                       | 14.684            | 16.919            | 21.666            | 27.877             |\n",
    "| 10                      | 15.987            | 18.307            | 23.209            | 29.588             |\n",
    "\n",
    "--- \n",
    "\n",
    "When the **chi-square statistic > critical value** we *reject the null hypothesis* (This is going to mean more later, but I'm introducing the term now. File this under the same promise I made above). \n",
    "\n",
    "When we reject the null hypothesis, we are confirming an association. \n",
    "\n",
    "Our value of ~1308 is much greater than the "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
