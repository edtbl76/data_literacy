{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "166a6f49-0ba7-4962-af89-230b88dcb1d6",
   "metadata": {},
   "source": [
    "# EDA 4 - Quantitative Bivariate Analysis\n",
    "\n",
    "In EDA 3, we did a bivariate analysis that compared a categorical variable and a quantitative variable. Now, we are going to compare two quantitative variables. \n",
    "\n",
    "We're going to use some rental data from the Texas area. Let's do our set up and some quick analysis before we **get to work!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca58441-8184-4bd6-bd0e-f15be93e2f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "rentals = pd.read_csv('texas_housing.csv')\n",
    "rentals.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f543212-33d7-46b4-b636-e1bd22f1f031",
   "metadata": {},
   "source": [
    "We have 7 variables\n",
    "\n",
    "- **price**: This is a numerical variable. Generally speaking, we consider price a *continuous* quantitative variable, because it is usually captured with the decimal values (cents). Here we see whole dollar values which makes it appear like a *discrete* value. For the sake of accuracy and continuity, we're going to treat it as a *continuous* variable. ```Remember... continuous is something we measure, discrete is something we count```\n",
    "- **type**: We know this is categorical. If there are only two values it is *binary*, if there are more its *nominal*. Generally speaking type variables are labels that provide information about the **observation**. An observation (scientifically speaking) is synonymous w/ row or record. It is common to use type as a means of mixed bivariate analysis, where we compare other variables against each type value.\n",
    "- **square_feet**: This is a quantitative variable. The column name itself is a unit of measurement, so this is a slam dunk. This is *continuous*. It is worth noting that even though we have a variable that is generally considered continuous, that doesn't mean it was named correctly or that it was captured correctly. Maybe square feet refers to the number of Minecraft characters with actual square feet. That would be *discrete*. If it was entered manually, the inches or fractions of inches might not have been captured, making the actual data more representative of a *discrete* variable.\n",
    "- **beds, baths**: These are both *discrete* quantitative values. We count bedrooms and bathrooms. Bathrooms are annoying. See rant below.  \n",
    "- **latitude, longitude**: these are *continuous* variables. They are values we measure.\n",
    "\n",
    "---\n",
    "**Bathroom Rant:**\n",
    "A half bath is a facade of continuity as a variable. If we want to nitpick this, it is a compound variable because the nature of a half bath communicates a type of bathroom or the \"features\" of the bathroom. We don't actually cut a bathroom in half. I'm going on this rant for two reasons: 1. I feel like it. 2. because being this pedantic about data analysis is important sometimes. \n",
    "\n",
    "What is the difference between a half and full bath? It comes down to the fixtures. Half the bathrooms have a toilet and a sink. If you are particularly observant, you might notice that these are usually located near the main or common living areas of a home. This is convenient for the more common uses of a bathroom during the day and for guests. A full bathroom includes a bathtub, shower, combo of the two or one of each. \n",
    "\n",
    "Put yourself in the position of a renter. How might these differences impact you? \n",
    "\n",
    "How would a single consultant who travels a lot view it? How would a family of 4 who love to entertain view it? \n",
    "\n",
    "---\n",
    "\n",
    "At any rate, let's take a closer look (at our data, not the bathrooms)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921bf682-068c-43b4-a734-7e85a05a0dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rentals.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1373d96a-1d16-452c-9635-44f362991093",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "You might notice that ```info()``` gives us the shape of the dataframe. We have 7 columns and a total of 4981 entires. \n",
    "\n",
    "The datatypes are ok. \n",
    "- Price and square feet as an int64 are fine. I'd prefer a float because the value is *continuous*, but if we don't have the fractional components of the value, there's no need to waste the storage. For the sake of accuracy we are going to change them. \n",
    "- Type is actually a string, but pandas encodes this as an object. we can recategorize this as a string. We'll look at this shortly\n",
    "- beds as an int are perfect.\n",
    "- baths as a float are annoying, but accurate due to the reasons I ranted about above.\n",
    "- lat and long are accurate as floats.\n",
    "\n",
    "Let's make our adjustments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cccc5dd4-4b94-4e5c-bd25-8231dfa37c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we're going to start by fixing price and square_feet\n",
    "rentals.price = rentals.price.astype('float64')\n",
    "rentals.square_feet = rentals.square_feet.astype('float64')\n",
    "rentals.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a592925-a6e8-4187-b77b-8cf93e5f29cd",
   "metadata": {},
   "source": [
    "Ok, we've taken care of our *continuous* variables...\n",
    "\n",
    "Now for the string. I didn't make a big deal about this in previous lessons but as I'm moving along, I'm trying to introduce new nuances piece by piece. \n",
    "\n",
    "#### What is the difference between 'string' and 'object' in pandas? \n",
    "\n",
    "String was specifically created and optimized for text data. This means that it supports operations that were designed for text (i.e. string manipulation like ```lower()``` or ```upper()```). It's also more memory efficient than an Object data type when storing text data. \n",
    "\n",
    "Object is a generic type. It can contain **any Python object**. As with most things, generalism tends to increase scope and reduce the ability to optimize for any one thing. This means that object is often less efficient at storing a given type of data than a dataytpe that was designed specifically for that type of data. \n",
    "\n",
    "\n",
    "#### When do I use String? \n",
    "\n",
    "There are two primary reasons. \n",
    "1. Performance. If you are dealing with a large amount of text data, this data type will be more performant.\n",
    "2. String manipulation. If the text data is ambiguous, consistently unclean (manual entry?) or has other needs that require you to wrangle around with it, this is a great reason.\n",
    "\n",
    "#### When can't I use it? \n",
    "\n",
    "1. compatibility. Unfortunately, older codebases, third party libs, or other languages might not recognize the string data type.\n",
    "2. **compatibility**. I'm emphasizing this, because many folks embarking on greenfield projects ignore third party libaries or polyglot environments, and then find themselves in troubling circumstances.\n",
    "3. Mixed data. If there are going to values in the dataset that aren't text data, you have to use an object. This is important to consider. Sometimes you can convert values to a string, and this can often be automated. This isn't always a good idea. If only 10% of the data is text-based, then we are optimizing all of the data towards a type that is only 1/10th of the actual data. It's a good bet that we the other 9/10s might not be well-suited for those optimizations.\n",
    "\n",
    "With all that said.. let's investigate the variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a655184-d2da-434c-9f94-63ff444a1078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, what are the values we've got? \n",
    "rentals.type.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c534b8b-5999-4cdd-8872-4f7253f0d3ad",
   "metadata": {},
   "source": [
    "---\n",
    "Ok, we've got 10 different types which helps us identify this as a *nominal* variable. All of the data is text based, and we know that this exercise is unlikely to leave this Jupyter notebook. \n",
    "\n",
    "We could say that changing the datatype is overkill based on that last sentence, but we're going to do it anyway as a means of practice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b42094a-37d9-4de5-8e11-6d69a54621db",
   "metadata": {},
   "outputs": [],
   "source": [
    "rentals.type = rentals.type.astype('string')\n",
    "rentals.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24fa104d-e4b4-4e70-bdde-98462dd47c74",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Let's take a quick look at the summaries of the data to see what the quality of the variables look like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af98211-2ecc-42e3-b041-1ffbaa61e60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rentals.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40bb2cc9-1642-4e07-8489-0a46d1d08b7e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "So, let's take a long hard look at this. (Sorry, we haven't gone this deep before). \n",
    "\n",
    "First I'm going to go through the summaries that are provided. \n",
    "- **count**: This is the number of observations (records, rows, whatever).\n",
    "- **unique**: This is only relevant for *categorical* variables. It tells you the number of unique variables. You can use this to identify *binary* variables.\n",
    "- **top**: this is the most frequently occurring value for a *categorical* variable.\n",
    "- **freq**: this is the actual frequency of the value idenfitied in **top**.\n",
    "- **mean, min and max**: we know what these *mean* (haha) by now!\n",
    "- **25,50,75**: These are the *median* and the boundaries of the *IQR*. We know what these mean too!\n",
    "- **std**: Standard Deviation. This is going to become more interesting in coming lessons, because standard deviations are used in evaluating spread. \n",
    "\n",
    "Some observations from the summaries: \n",
    "- we have 4981 observations, but 4936 for **latitude/longitude**, which appears to be missing 45 observations?. We'll dig into this.\n",
    "- we'll use ```value_counts()``` to validate the **top/freq**\n",
    "- **mean,median,25,75** and **std** are all fairly difficult to evaluate from ```describe()``` unless you have intimate domain knowledge. We usually need some form of visualization to take a look at the trends and shape of the data in addition to some understanding of the meaning of that data in order to perform any analysis of these values.\n",
    "- **min** and **max** are more useful from this view because they represent the absolute top and bottom of the ranges of values. This is where mistakes, inaccuracies and outliers tend to live. Unless you've committed the map of the planet to memory, it's unlikely you'll be able to pick out long/lat by the naked eye. We can probably look it up, but most of the values appear continuous, so I doubt that there are any errors there. Looking across the variables for **max** most of the values appear fairly reasonable. **min** however shows a few areas that are worrisome. A $1 apartment, 1 square foot and 0 beds/0 bath are either a mistake or a smartass trying to rent out a shoebox. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e4403c-257a-40e6-8bbe-14a1939ce1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's look at latitude and longitude\n",
    "rentals.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c81553-6b0b-443f-80be-96cc60f45938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# found some! Let's take a closer look at these values\n",
    "rentals[rentals.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152ee431-fc58-45a9-9712-3c2812bd419d",
   "metadata": {},
   "source": [
    "---\n",
    "Okay, we've found the null values and examined them across each observation. There doesn't appear to be any rhyme or reason. The values might have just been left out. \n",
    "\n",
    "```A possible reason for missing long/lat values on locations is new construction or new street location. Many APIs for companies like Zillow or Redfin pull this information based on GIS. Some new locations haven't been registered, so it's a possible reason for the missing value.```\n",
    "\n",
    "Let's go ahead and validate the top/freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df66727-3467-4340-ad73-998ef5d4dddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "rentals.type.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ba5423-5001-4c43-8b66-3936230de4ae",
   "metadata": {},
   "source": [
    "---\n",
    "Awesome. This checks out. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1377ab92-58cc-4a7c-883c-11c7b9d057b9",
   "metadata": {},
   "source": [
    "### Scatter Plots: Viewing Numbers Against Numbers\n",
    "\n",
    "Scatter plots are a great way to find a linear relationship between two quantitative variables across multiple observations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f90a700-4e05-4f3d-868a-d038ef9bab37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to import our handy lib to do the vis work.\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.xlabel('Number of Beds') \n",
    "plt.ylabel('Square Footage')\n",
    "plt.scatter(x=rentals.beds, y=rentals.square_feet)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de61a677-6f84-4c52-a35b-b14b047a1509",
   "metadata": {},
   "source": [
    "You'll notice that we have what looks periodic, because the plot isn't continuous. This is because the number of beds is a discrete variable. This is a normal phenomenon when working with discrete variables. \n",
    "\n",
    "The advantage of discrete variables is that it makes relationships between each discrete variable very clear. \n",
    "\n",
    "\n",
    "**Observations:**\n",
    "- We can see several observations of unreasonably low square footage and 0 beds. \n",
    "- Generally, we see that an increase in square footage shows an increase in the number of bedrooms. This makes sense, because bedrooms take up space, so more bedrooms would (reasonably) increase the square_footage of a rental.\n",
    "- The 7 bedrooms looks like an outlier based on its separation from the rest of the data.\n",
    "- The 5 bedrooms is fairy interesting, because it's clumped around a few square footage values. This could be due to the lack of samples related to the details of the offerings (i.e. a particular apartment complex layout that offers these features,etc.)\n",
    "\n",
    "#### Why do we use scatter plots? \n",
    "\n",
    "I told you already! We use it to try to define and identify relationships and associations between 2 quantitative variables. Our eyes are powerful machines for analysis; however, our brains can easily make mistakes perceiving this information and we are prone to picking out patterns that aren't actually there. This means we need some other tools to validate our findings. Math tends to help out..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88dec8e-cffd-48bd-892e-65704c166c37",
   "metadata": {},
   "source": [
    "### Covariance\n",
    "\n",
    "This is summary statistics that describes the *strength* of a linear relationship between observations across multiple variables. \n",
    "\n",
    "- **positive** covariance is a linear relationship that draws from the bottom left to the top right of a scatter plot. This shows a relationship between larger values of one variable and larger values of another. A good example, might be height and pants size.\n",
    "- **negative** covariance is a linear relationship that draws from the top left to the bottom right. This shows a relationship between larger values of one value and smaller values of the other. This is also known as an *inverse proportional* relationship. A good example might be as external temperature goes down, heating costs go up.\n",
    "- **zero** covariance is when a scatter plot looks...scattered. There is no discernable linear relationship\n",
    "\n",
    "\n",
    "\n",
    "![Covariance Figure](./covariance_fig1.svg)\n",
    "\n",
    "*Figure 1: Demonstrates Scatter Plot and Covariance*\n",
    "\n",
    "What a covariance matrix looks like for two (or more) variables. \n",
    "\n",
    "| | variable 1 | variable 2 | \n",
    "|-|-|-|\n",
    "| variable 1 | variance (variable 1) | covariance | \n",
    "| variable 2 | covariance | variance (variable 2) |\n",
    "\n",
    "Let's explain these values to understand how the matrix is calculated. \n",
    "\n",
    "**variance**\n",
    "For a population, we divide the sum of *squared deviations* by the number of data points\n",
    "For a sample, we divide by n - 1 (This is called **Bessel's correction**.) I'm going to hand wave over the theory right now, but generally speaking we rarely have access to an entire population, so we more often than not will be using this calculation. \n",
    "\n",
    "**TBD add the math equations??**\n",
    "\n",
    "\n",
    "Let's assume we have a data set of ```[1,2,3,4,5]``` for variable 1 and ```[2,4,6,8,10]``` for variable2. \n",
    "\n",
    "1. We have to calculate the mean\n",
    "\n",
    "variable 1: (1 + 2 + 3 + 4 + 5) / 5 = 15 / 5 = **3**\n",
    "\n",
    "variable 2: (2 + 4 + 6 + 8 + 10) / 5 = 30/5 = **6**\n",
    "\n",
    "2. We calculate the *deviation* of each mean, which is subtracting the mean from each data point.\n",
    "\n",
    "variable 1\n",
    "- 1 - 3 = **-2**\n",
    "- 2 - 3 = **-1**\n",
    "- 3 - 3 = **0**\n",
    "- 4 - 3 = **1**\n",
    "- 5 - 3 = **2**\n",
    "\n",
    "variable 2\n",
    "- 2 - 6 = **-4**\n",
    "- 4 - 6 = **-2**\n",
    "- 6 - 6 = **0**\n",
    "- 8 - 6 = **2**\n",
    "- 10 - 6 = **4**\n",
    "\n",
    "3.  Now we square each deviation *note: this is one method for ensuring that negative/positive values don't cancel each other out. However, one of the limitations of using squared values is that the results are no longer related to the context of the data point, i.e. they are hard to interpret. This is one of the reasons that the **mean absolute deviation** uses the absolute value*\n",
    "\n",
    "variable 1 = ```[4, 1, 0, 1, 4]```\n",
    "variable 2 = ```[16, 4, 0, 4, 16]```\n",
    "\n",
    "*When you compare this to the initial data points and even the deviations alone, you can see the skew that is beginning to happen*\n",
    "\n",
    "4.  Add up the squared deviations. (This is the part that led to step 3. Summing positive and negative values after calculating deviations often leads to canceling out values in normal distributions.)\n",
    "\n",
    "variable 1: **10**\n",
    "variable 2: **40**\n",
    "\n",
    "5.  Let's do the final calculation.\n",
    "\n",
    "If this were the entire population: \n",
    "- variable 1: 10 / 5 = **2**\n",
    "- variable 2: 40 / 5 = **8**\n",
    "\n",
    "If this were a sample, we use Bessel's correction:\n",
    "- variable 1: 10 / (5 - 1) = **2.5**\n",
    "- variable 2: 40 / (5 - 1) = **10**\n",
    "\n",
    "**covariance**\n",
    "This is the calculation we are looking for. It involves measuring the degree to which two variables change together. \n",
    "\n",
    "1. We need to calculate the mean (we did that already)\n",
    "\n",
    "variable 1: **3**\n",
    "\n",
    "variable 2: **6**\n",
    "\n",
    "2. We calculate the *deviations* from the mean. (we did that too!)\n",
    "\n",
    "variable 1: ```[-2, -1, 0, 1, 2]```\n",
    "variable 2: ```[-4, -2, 0, 2, 4]```\n",
    "\n",
    "3. Now we multiply the associated deviations from variable 1 against variable 2.\n",
    "\n",
    "co-products: \n",
    "- -2 * -4 = **8**\n",
    "- -1 * -2 = **2**\n",
    "- 0 * 0 = **0**\n",
    "- 1 * 2 = **2**\n",
    "- 2 * 4 = **8**\n",
    "\n",
    "4. Calculate the sum of those values\n",
    "\n",
    "8 + 2 + 0 + 2 + 8 = **20**\n",
    "\n",
    "5. The final calculation is the same for covariance as it is for variance. We divide by *n* for whole populations or **Bessel's correction** *(n-1)* for samples.\n",
    "\n",
    "for a population: 20 / 5 = **4**\n",
    "for a sample 20 / (5 - 1) = **5**\n",
    "\n",
    "---\n",
    "\n",
    "This is a lot of math, but python does this work for us. We're going to calculate the variance of each variable,then we're going to calculate the covariance to validate the variance calculations as well as obtain the variance. (Use the table provided above to decypher the matrix output of ```cov()```)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9986f2b-8593-42a0-9b2c-e86910e8b2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First let's show bedrooms\n",
    "rentals.beds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc4e499-a8a4-47e1-a093-d72ee771f9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's calculate the mean for beds and use that mean to calculate the deviations. \n",
    "beds_mean = rentals.beds.mean() # Rawr\n",
    "beds_deviations = rentals.beds - beds_mean\n",
    "\n",
    "print(f'Mean - Bedrooms: {beds_mean}')\n",
    "print(f'Deviations - Bedrooms: ')\n",
    "beds_deviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9e7c64-82ae-459d-a3fe-31fe12fa2875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick inspection checks out looks good.. let's keep going. \n",
    "\n",
    "# Now we need to calculate the squared deviations before we sum them. \n",
    "beds_squared_deviations = beds_deviations.apply(lambda x: x * x)\n",
    "beds_squared_deviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf619e1-93be-4886-b9c4-31005c8f9540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another quick inspection looks good... let's keep going\n",
    "\n",
    "# calculate the sum of the squared deviations. \n",
    "sum_beds_squared_deviations = beds_squared_deviations.sum()\n",
    "sum_beds_squared_deviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c135583a-2c65-4bd4-9e71-5cf083843eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's bring it home. We're going to calculate it for a sample or population and print both\n",
    "n = len(rentals.beds)\n",
    "print(f'Variance of Bedrooms (Population): {sum_beds_squared_deviations / n}')\n",
    "print(f'Variance of Bedrooms (Sample)    : {sum_beds_squared_deviations / (n - 1)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f2bf69-2de3-438a-9559-8c0758ac7ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's check our work. \n",
    "rentals.beds.var()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b872ef3-bf23-45e4-99f2-f625cb1cb729",
   "metadata": {},
   "source": [
    "---\n",
    "We've learned a few things\n",
    "1. the ```var()``` method assumes you are using a sample, not the full population. For many statistics this is a good assumption.\n",
    "2. there is a ```var()``` method that makes this so so so much easier.\n",
    "3. I like to tell you about those things after making you do the hard part.\n",
    "4. The manual calculation is different than the direct calculation. This is due to some rounding, truncating and general screwyness w/ math in python (and any programming language). The rule of thumb is trust the direct method... ```var()```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82041032-2e55-42c2-a528-c7026ce0ce00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We're going to repeat the steps for square footage, but I will do it all in a single notebook cell. \n",
    "sqft_mean = rentals.square_feet.mean() # Rawr! mean square feet.\n",
    "sqft_deviations = rentals.square_feet - sqft_mean\n",
    "sqft_squared_deviations = sqft_deviations.apply(lambda x: x * x)\n",
    "sum_sqft_squared_deviations = sqft_squared_deviations.sum()\n",
    "n = len(rentals.square_feet)\n",
    "population_variance = sum_sqft_squared_deviations / n\n",
    "sample_variance = sum_sqft_squared_deviations / (n - 1)\n",
    "\n",
    "print(f'Square Feet Values: ')\n",
    "print(rentals.square_feet)\n",
    "print()\n",
    "print(f'Mean Square Footage: {sqft_mean}')\n",
    "print()\n",
    "print(f'Square Feet Deviations: ')\n",
    "print(sqft_deviations)\n",
    "print()\n",
    "print(f'Square Feet Squared Deviations: ')\n",
    "print(sqft_squared_deviations)\n",
    "print()\n",
    "print(f'Sum of Squared Deviations: {sum_sqft_squared_deviations}')\n",
    "print(f'Square Footage Variance (Population): {population_variance}')\n",
    "print(f'Square Footage Variance (Sample)    : {sample_variance}')\n",
    "# Go through the output and check to make sure everything makes sense to you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06616fd-b0f1-4843-b533-a06729e0cbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's calculate the variance to check our work!\n",
    "rentals.square_feet.var()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3209466-d1b4-4745-848c-2ce658b00b6f",
   "metadata": {},
   "source": [
    "You probably noticed the discrepancy again. (Trust the direct method!) \n",
    "\n",
    "---\n",
    "\n",
    "Let's go through the same exercise w/ covariance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19de8fe3-295d-4e0f-8636-23765b1007ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's just print out the mean for bedrooms and square footage to remind ourselves\n",
    "\n",
    "# Note if you hit tab when typing, the in scope variable swill show up in the tab completion drop down. Very handy!\n",
    "\n",
    "print(f'Mean - Bedrooms        : {beds_mean}')\n",
    "print(f'Mean - Square Footage  : {sqft_mean}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97a0d84-8298-4edb-b590-d7b7cc3a2cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's print out the deviations for each of our variables\n",
    "\n",
    "print(f'Deviations - Bedrooms: ')\n",
    "print()\n",
    "print(beds_deviations)\n",
    "print()\n",
    "print(f'Deviations - Square Footage: ')\n",
    "print()\n",
    "print(sqft_deviations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c0ca1f-fb05-4c3b-aec8-34067265b006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's create the product of the deviations\n",
    "product_of_deviations = beds_deviations * sqft_deviations\n",
    "product_of_deviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d691ea49-67be-42ff-828e-dbe0f62bdfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the sum of the products\n",
    "sum_of_product_of_deviations = product_of_deviations.sum()\n",
    "sum_of_product_of_deviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68076d87-ba55-419d-8378-118d1c3ff020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate covariance for pop and sample. \n",
    "n = len(rentals)\n",
    "population_covariance = sum_of_product_of_deviations / n\n",
    "sample_covariance = sum_of_product_of_deviations / ( n - 1 )\n",
    "\n",
    "print(f'Population Covariance  :  {population_covariance}')\n",
    "print(f'Sample Covariance      :  {sample_covariance}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9b71c6-57d8-4d8b-b1e7-6ddf615c5d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check out our work! (Don't worry about the usage of the cov() method just yet) \n",
    "\n",
    "# this is where we calculate covariance\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "covariance = np.cov(rentals.beds, rentals.square_feet)\n",
    "covariance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4954177-aa8d-49ef-aa12-7acfde2f6670",
   "metadata": {},
   "source": [
    "Ok, that is some ugly output. \n",
    "\n",
    "We can see our variance for beds (top left) is accurate\n",
    "We can see our variance for square feet (bottom right) is accurate. \n",
    "Covariance (top right, bottom left) are accurate. \n",
    "\n",
    "Let's fix the output by playing w/ ```numpy.set_printoptions()```. There are two settings you'll likely use fairly often to generate cleaner output\n",
    "- ```suppress=True``` This prints floating point numbers as fixed point notation. This is especially useful for displaying zero. Due to the limitations of coding languages, we often end up with values that equate to zero, but are reflected as tiny values in scientific notation. We usually don't want that.\n",
    "- ```precision=#```: This is the decimal precision we'd like to see. It's usually not forever. :) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9143cd-0a34-4bae-8353-1839e3121e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True, precision=3)\n",
    "covariance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6de799d-cf17-4ced-a45a-8b6f2ec748bb",
   "metadata": {},
   "source": [
    "Neat. Math!\n",
    "\n",
    "What it tells us\n",
    "- Positive covariance tells us that there is an association and it's proportional. As numbers increase in one variable, they tend to increase in the other. We kind of saw that in the scatter plot.\n",
    "- The magnitude (or value) indicates the strength of the relationship.\n",
    "\n",
    "What it does **not** tell us: \n",
    "- The magnitude is actually kind of useless. Even though it indicates the strength of the relationship, it's not every easy for us to interpret or compare between different pairs of variables.\n",
    "\n",
    "\n",
    "Do you know why? Let's look at the variables to come up w/ some answers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66a488a-7b22-4e61-b826-29de750c2f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's calculate the range of bedrooms\n",
    "rentals.beds.max() - rentals.beds.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49bdd6e-75ce-43f2-b4f0-d909bc05f573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do it again for square footage\n",
    "rentals.square_feet.max() - rentals.square_feet.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588b2380-d317-41cf-a253-e394f43a1b9c",
   "metadata": {},
   "source": [
    "Have you figured it out yet??\n",
    "\n",
    "Exactly. The values of each variable aren't standardized, so strength is just \"some number\" calculated based on two other numbers. You could say that we've basically removed the meaning from the variables. \n",
    "\n",
    "So how do we get it back..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba291f0-5547-43cd-bc2f-2e43f56bc8db",
   "metadata": {},
   "source": [
    "### Correlation \n",
    "\n",
    "**Pearson Correlation** is a scaled form of covariance. It still uses positive and negative values to measure proportional and inverse proportional relationships as well as a 0 value to measure no relationship. \n",
    "\n",
    "![Pearson Correlation](./correlation_fig_1.svg)\n",
    "\n",
    "*Example of Pearson Correlation*\n",
    "\n",
    "However, it normalizes the values to a range of -1 to +1 making comparisons appropriate. \n",
    "\n",
    "While there is no hard and fast rule about the magnitude and it's interpretation of strength, there is a general rule of thumb: \n",
    "- 0 is **absolute no correlation**\n",
    "- values exceeding +/- 0.3 are considered to have a linear correlation\n",
    "- values exceeding +/- 0.6 are considered to have a *strong* linear correlation\n",
    "\n",
    "\n",
    "Let's calculate the correlation of our variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df113212-6179-4f8f-9417-348ab112b8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Ignore the syntax for now, we'll talk more about correlation later)\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "correlation_beds_square_feet, p = pearsonr(rentals.beds, rentals.square_feet)\n",
    "correlation_beds_square_feet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0517fe66-3782-4fc3-9cfb-ffdef244add8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's display out scatter plot again to compare it to that value\n",
    "plt.xlabel('Number of Beds') \n",
    "plt.ylabel('Square Footage')\n",
    "plt.scatter(x=rentals.beds, y=rentals.square_feet)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075b4f50-130c-470a-9096-882676a6a592",
   "metadata": {},
   "source": [
    "What do you think? \n",
    "\n",
    "The correlation calculation suggests that there is a strong positive correlation between beds and square footage? \n",
    "- We certainly see values moving from bottom left to top right, so this is a proportional or positive relationship.\n",
    "- Strong? If you ignore those zero-based outliers, the range of values of square footage appears consistent as we increase the number of bedrooms. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2adae39f-501e-4d53-8998-57b61e43676f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Limitations of Covariance and Correlation\n",
    "\n",
    "**Covariance** and **correlation** are great tools for evaluating associations between two variables. However, and this is important to remember, they measure the strength of **linear** relationships with **non-zero** slopes. \n",
    "\n",
    "This means that the results can be misleading for other types of relationships. \n",
    "\n",
    "![Examples of Misleading Results of Correlation](./correlation_fig_2.svg)\n",
    "\n",
    "*Example of Misleading Results from Correlation*\n",
    "\n",
    "Let's demonstrate a quick example of this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e16b9d-3d52-45bf-8f50-70190595ec51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the data and take a quick look at the data. \n",
    "sleep = pd.read_csv('sleep_study.csv')\n",
    "\n",
    "sleep.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9650a0-5e6d-4d4c-a054-78bf98d8d27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is the shape of the data, null vals, data types etc. \n",
    "sleep.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73cfc621-b270-4851-b309-5303aa946c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick summary. \n",
    "sleep.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a462cb1c-8b87-4b34-8ef5-4b1971d80df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's calculate the covariance\n",
    "covariance_sleep = np.cov(sleep.hours_sleep, sleep.performance)\n",
    "covariance_sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9f7d3d-aec1-490e-84f8-c196623f2fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's calculate the correlation\n",
    "sleep_corr, p = pearsonr(sleep.hours_sleep, sleep.performance)\n",
    "sleep_corr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49639f37-ea18-49a1-8e9b-20ba0b0c7305",
   "metadata": {},
   "source": [
    "This is less than 0.3, so we can expect this to have a very small amount of correlation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a62bce5-4b32-4917-a3af-ccb5ec40810e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's prove it by plotting it out...\n",
    "plt.scatter(sleep.hours_sleep, sleep.performance)\n",
    "plt.xlabel('Hours of Sleep')\n",
    "plt.ylabel('Performance')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546d202f-8bbd-44d2-9e68-5023d56f89f1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Oops. We can see that the data points have a clear relationship, it's just not linear. \n",
    "\n",
    "As hours of sleep approach 8, performance also increases. However, once hours of sleep continues to increase beyond 8, performance decreases, suggesting that too much sleep is bad!!!\n",
    "\n",
    "This is a good example of the limitations of pearsons correlation and covariance. (Technically the result is accurate in that it suggests there is a weak **linear** association. This is why the result is misleading. Many engineers and scientists might assume that this means there is simply poor association altogether. \n",
    "\n",
    "E"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
