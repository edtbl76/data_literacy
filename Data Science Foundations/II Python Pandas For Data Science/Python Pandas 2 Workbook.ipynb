{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cda06c92-a435-444c-a114-b30b9922f516",
   "metadata": {},
   "source": [
    "# What can we do with pandas? Part Deux\n",
    "\n",
    "We'll be working with our favorite folks on the court, the Boston Celtics. \n",
    "\n",
    "Let's set up our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665a6c20-be15-494c-a282-f3dec9f7c365",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "celtics = pandas.read_csv('boston_celtics_2023_2024.csv')\n",
    "celtics.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c88198b-c9f1-4d70-941a-c0ec9fc3ebb3",
   "metadata": {},
   "source": [
    "We're going to go through each of the fields, but we're going to start small. \n",
    "\n",
    "Let's look at country_code. This is in lower case. It's more common to see this as an upper case field, so let's change that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b647d7-4bfa-4970-91a5-392dc61139a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Simple String Operations\n",
    "\n",
    "import string \n",
    "\n",
    "celtics.country_code = celtics.country_code.apply(str.upper)\n",
    "celtics.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c33342-4b4b-4ece-b73f-86f58b6b93ef",
   "metadata": {},
   "source": [
    "Much better. Let's also inspect the data frame. Pay close attention to the Non-Null Count. \n",
    "(Do you remember how to find that NaN value from the last lesson? Who didn't go to college?!?!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e8996a-8728-4957-bb8e-909c9d7cf61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "celtics.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a929da4-3710-4cd0-9e4b-cdbff4a84d7b",
   "metadata": {},
   "source": [
    "Let's look at JD Petersen for a second...(Remember how to select a single Series?) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8b464f-f84d-40f2-b27d-996b672babd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "celtics[celtics.player.str.contains(\"Drew\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2715577e-8d0b-4870-95b0-bbd855fa8d94",
   "metadata": {},
   "source": [
    "Drew has 2 universities listed. Let's change the column name to colleges. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a98adf-7313-4b66-8b22-30ecb7918d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "celtics.rename(columns={\"college\": \"colleges\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e7e430-196b-40f7-ab65-89fb9dbe139d",
   "metadata": {},
   "source": [
    "```\n",
    "Note: we can change all of the column names as well:\n",
    "\n",
    "celtics.columns = [<list of new column names>]\n",
    "\n",
    "This syntax requires you to specify all of the column names.The previous example above using DataFrame.rename() allows\n",
    "selecting renaming and is more common.\n",
    "```\n",
    "\n",
    "There are a number of reasons for doing this. Sometimes source data has column names w/ spaces or that start w/ numbers or other limitations that prevent us from using dot notation. We might rename columns to fix this, because dot notation tends to be less error prone than bracket notation. \n",
    "\n",
    "Another reason is presentation. After all of your data wrangling is finished, you might want to output new column names that reflect some polish. This is the most common use of DataFrame.columns, because it's more likely that all of the columns will be renamed to fit presentation requirements. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b834f523-280c-44ae-805b-46cc06b35bdb",
   "metadata": {},
   "source": [
    "### Adding Columns by merging data frames\n",
    "\n",
    "We could add a single column, but we will be doing that a bit later, and I want to add some data to make this more involved, so let's add a second. Before we can do that, let's create the data frame and figure out a good field to merge them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e8220b-5ca3-453e-932b-7bf971fa2140",
   "metadata": {},
   "outputs": [],
   "source": [
    "totals = pandas.read_csv('boston_celtics_2023_2024_totals.csv')\n",
    "totals.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b4e21c-7d29-48ca-ab87-5775ef211e06",
   "metadata": {},
   "source": [
    "Yikes. Not much to play with. We only have 2 options. \n",
    "1. We can use the player name, which is usually going to be unique on a sports team (at least within a given season).\n",
    "2. We could calculate the age of the player from the first data frame based on their birthdate and match it to their age in this data frame. The downside is that we don't really know how it's been calculated (what if they had a birthday mid-season? Is this current? etc.)\n",
    "\n",
    "For our purposes, players is the best way to do this right now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32a32ff-7b8f-42ed-95e0-c3b18de8c584",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Using an \"outer\" method, which is similar to a SQL full outer join so we get all of the data. \n",
    "celtics = pandas.merge(celtics, totals, on='player', how='outer')\n",
    "celtics.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb529310-476f-4c1c-8e2b-d674d23d0aa4",
   "metadata": {},
   "source": [
    "Whoa, nellie! That certainly added a ton of data, and I imagine you can start to pick out some problems. \n",
    "Let's look at the DataFrame's structure and the data types. \n",
    "\n",
    "Pay attention to the non-null values. This is one of the common results of merging data frames or tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926df0fc-9476-47e5-85c2-a4781a10da61",
   "metadata": {},
   "outputs": [],
   "source": [
    "celtics.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b59d6fc-68b5-44a1-9c83-cd3c750960a2",
   "metadata": {},
   "source": [
    "### Brief Note On Display options. \n",
    "Hmm... we can't see all of our columns. \n",
    "\n",
    "Let's change that..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6a4f6a-31cf-469d-9cff-cc530f150b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas.options.display.max_columns = None\n",
    "pandas.options.display.max_rows = None\n",
    "\n",
    "celtics.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92aafa80-f609-4613-ac9f-1ade3ac48dc3",
   "metadata": {},
   "source": [
    "### Creating a new column from derived data. \n",
    "\n",
    "As you can see, we have a considerable number of pre-calculated fields. (Thanks to the wonderful folks at ![basketball-reference.com](https://basketball-reference.com).) \n",
    "\n",
    "However, they left a few for us to play with. We only have total points, but points-per-game is a common statistic. Let's start by looking at the columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2de94e0-936d-4e6f-b13c-4dd5c81118ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "celtics[['player', 'G', 'PTS']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219c2809-b6be-4db7-b63d-8a308202cdd6",
   "metadata": {},
   "source": [
    "We're going to create a new column called 'PPG' for Points Per Game. We're going to compute the data based on The information we just queried\n",
    "\n",
    "Afterwards, let's sort the results in descending order based on the highest point scorers per-game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e878662c-7b5c-420d-9cce-6705e1ec9854",
   "metadata": {},
   "outputs": [],
   "source": [
    "celtics['PPG'] = celtics.PTS / celtics.G\n",
    "celtics[['player', 'G', 'PTS', 'PPG']].sort_values(by=['PPG'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2673abf6-0609-49bd-9168-b0a5d9e30453",
   "metadata": {},
   "source": [
    "### Lambdas (Python) to create columns\n",
    "\n",
    "That player column is bugging me. I'd like to split that up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321efdba-26d5-4a15-999f-e37ba6ebb680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create some lambdas to do work for us\n",
    "get_first_name = lambda word: word.split(' ')[0]\n",
    "get_last_name = lambda word: word.split(' ')[1]\n",
    "\n",
    "# This is a little bit more challenging. You have to use the negative index to avoid a 'list index out of range'\n",
    "get_suffix = lambda suffix: suffix.split(' ')[-1] if len(suffix.split(' ')) > 2 else 'null'\n",
    "\n",
    "# Create the new columns\n",
    "celtics['first_name'] = celtics.player.apply(get_first_name)\n",
    "celtics['last_name'] = celtics.player.apply(get_last_name)\n",
    "celtics['suffix'] = celtics.player.apply(get_suffix)\n",
    "\n",
    "celtics[['player','first_name','last_name','suffix']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9e0a06-99db-4613-9d9e-4350b3eecedf",
   "metadata": {},
   "source": [
    "### Working with Rows. \n",
    "\n",
    "So we can similarly work with rows in a similar manner, where we perform calculations on a row in order to create a new column or value. \n",
    "\n",
    "One of the most common sources of confusion in basketball statistics is FG (Field Goals or shots), FT (Free Throws), 3P (Three Pointers) and PTS.\n",
    "\n",
    "1. a Free Throw is worth a single point. It is not a Field Goal\n",
    "2. Field Goals are 2 or 3 PT shots\n",
    "3. 2 Point shots aren't reflected as a separate statistic, you have to pull them out... so let's do that.\n",
    "\n",
    "\n",
    "We're going to need 3 new columns: \n",
    "1. 2P - this will be the 2 pointers made, which = FG - 3P\n",
    "2. 2PA - this is 2 pointers attempted, which is FGA - 3PA\n",
    "3. 2P% - this is 2-Pt percentage, which is FG / FGA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ee1a11-7fe5-4371-bacb-d185f13851f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our python lambdas for 2P and 2PA (NOTE. We can't use dot notation w/ column names that start\n",
    "# with a number)\n",
    "get_2P = lambda row: row.FG - row['3P']\n",
    "get_2PA = lambda row: row.FGA - row['3PA']\n",
    "\n",
    "# create the new columns (make sure to set the axis to ROWS, axis=1!!!)\n",
    "celtics['2P'] = celtics.apply(get_2P, axis=1)\n",
    "celtics['2PA'] = celtics.apply(get_2PA, axis=1)\n",
    "\n",
    "celtics[['last_name', '2P','2PA']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56b86d8-682a-41bf-bc30-b3bb589d0417",
   "metadata": {},
   "source": [
    "Cool. That's done, so let's perform the calculation to get the percentage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b212fc63-62ca-4746-af45-7e657845a692",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_2PPct = lambda row: row['2P'] / row['2PA']\n",
    "celtics['2P%'] = celtics.apply(get_2PPct, axis=1)\n",
    "celtics[['last_name', '2P','2PA', '2P%']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d378a3-52c9-48b9-b372-a47611b83e0a",
   "metadata": {},
   "source": [
    "Let's output the entire DataFrame to finish up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db10fb2-5edd-4bc6-9a1a-fd9277411225",
   "metadata": {},
   "outputs": [],
   "source": [
    "celtics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
