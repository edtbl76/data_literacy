{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f89193ab-8e91-4c30-91e3-5eaa21bd06d3",
   "metadata": {},
   "source": [
    "# Python Pandas 4 -- Working w/ Multiple Data Frames\n",
    "\n",
    "We looked at merging briefly in the previous examples (mostly because the data I selected called for it!). Here we're going to look at something a little bit more focused. \n",
    "\n",
    "### Setup\n",
    "Let's start by setting up our environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbf668f-bdc0-4ef2-9fd0-aeff0278e420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas \n",
    "# in many examples and codebases you'll find statements that alias the import (i.e import pandas as pd). \n",
    "# I don't like doing this due to the ambiguity. Autocomplete protects our fingers. \n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0763fa47-4d47-452f-806b-066c6213f040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# orders\n",
    "orders = pandas.read_csv('orders.csv')\n",
    "orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d47e9ae-2923-45c3-9399-965983edff61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# customers\n",
    "customers = pandas.read_csv('customers.csv')\n",
    "customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c314934-d6bc-4fcd-9381-4591457b67e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# products\n",
    "products = pandas.read_csv('products.csv')\n",
    "products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f6adb1-2c41-466a-96f0-397041494e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# monthly_sales\n",
    "sales = pandas.read_csv('monthly_sales.csv')\n",
    "sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48722e17-fe85-4370-9670-f76b1906c87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# monthly sales targets\n",
    "targets = pandas.read_csv('monthly_targets.csv')\n",
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cfd862-b3c7-4ab4-a5b9-5bed68c8347f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a comparison of east vs. west regions \n",
    "east_vs_west = pandas.read_csv('east_vs_west.csv')\n",
    "east_vs_west"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1e6159-b6bb-4e9e-9e52-ebbd110966ee",
   "metadata": {},
   "source": [
    "### Inner Merge\n",
    "\n",
    "Let's just create a basic inner merge. (This is the default merge, so we don't have to specify it, but if we decide to do it anyway it would be **how='inner'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3672c9-e90b-4518-ab45-d4ae92541eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparing sales and targets\n",
    "sales_and_targets = pandas.merge(sales, targets)\n",
    "sales_and_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d229f6-b1ca-4ab3-8602-d6256f35c499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can do different things like calculate the difference\n",
    "sales_and_targets['difference'] = sales_and_targets['revenue'] - sales_and_targets['target']\n",
    "sales_and_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7252692-5bb8-48f1-a4e4-87f439fb9880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... or separate out the months we're over \n",
    "sales_and_targets[sales_and_targets.difference > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bb6da2-571f-406b-ab87-0fbf8d82e9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (We didn't need to create a new column to do this...) \n",
    "sales_and_targets[sales_and_targets.revenue > sales_and_targets.target]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c82a24-aacf-4ce7-8ed0-8b3a31ce24b6",
   "metadata": {},
   "source": [
    "Our previous merges have been performed on DataFrame's merge() method, however each instance of the DataFrame has it's own merge() method. This is the preferential method for merging dataframes when you are going to chain more than 2 dataframes together. (Basic Chain of Responsibility). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcdb36d5-eac8-4bef-812c-78fff5aeda42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's chain our sales data\n",
    "chained_sales = sales.merge(targets).merge(east_vs_west)\n",
    "chained_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657982a4-479d-4680-a3ee-9323724d818b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can now perform complex filters on multiple data frames\n",
    "chained_sales[(chained_sales.revenue > chained_sales.target) & (chained_sales.east > chained_sales.west)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71e0f9e-4bfb-42e5-9fa6-d2df59b82424",
   "metadata": {},
   "source": [
    "### Merging on specific columns\n",
    "\n",
    "Prior to this, the examples automatically merged on the columns that made sense, because there was only a single shared column name. This is a neat feature of pandas. (That can be painful when working w/ many datasets that you aren't familiar with. **ALWAYS INSPECT YOUR DATA**\n",
    "\n",
    "Its far more common that you'll find data frames that don't have shared column names (or if they do, the column names don't have the same semantics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952c60c8-2340-4f2d-a31b-cf037c48db74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets take a look at our orders and product data frames. I know, we looked at them above.. \n",
    "print(orders)\n",
    "print(products)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932c0bcc-42b4-426c-8bf9-a8ebb7b5024d",
   "metadata": {},
   "source": [
    "\n",
    "We have no common column names in this case, but we have a foreign key relationship between **orders.product_id** and **products.id**. This means we have a way to merge the two frames... but how?  \n",
    "\n",
    "The simplest solution would be to make the names match so that pandas can work its black magic!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfa79a4-0eaf-4d42-aab1-b31ec830efb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution 1: Trust the Black Magic -- rename your columns. \n",
    "orders_and_products = pandas.merge(\n",
    "    orders,\n",
    "    products.rename(columns={'id':'product_id'})\n",
    ")\n",
    "orders_and_products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c6eb99-f9e7-40ce-83b2-affeb89ddf48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution 2: A more SQL-like solution -- use merge, but specify the column relationship\n",
    "## Suffixes are ways for pandas to resolve columns w/ the same name. It won't allow this. \n",
    "## The suffixes tell you where they've originated from (the defaults are _x and _y)\n",
    "orders_and_products = pandas.merge(\n",
    "    orders,\n",
    "    products,\n",
    "    left_on='product_id',\n",
    "    right_on='id',\n",
    "    suffixes=['_orders','_products'])\n",
    "orders_and_products"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7ccf6c-ae03-43af-9552-19b24bad92d7",
   "metadata": {},
   "source": [
    "Let's show how merges go wrong... (let's look at products and orders again)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4950785e-68da-4ac3-b32a-7d67048faa06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I lied, let's look at a different example of orders\n",
    "orders2 = pandas.read_csv('orders2.csv')\n",
    "orders2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2bd95d-6611-4ff4-b81f-9e46f6b62c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "products"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5002f0-9b61-49f0-9c60-a720d6995b27",
   "metadata": {},
   "source": [
    "Did you notice that there is a **product_id=5** that corresponds to **order_id=3**?? \n",
    "However, there that **product_id** doesn't exist in the product dataframe.\n",
    "\n",
    "Let's do a default inner merge to see waht happens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b8d220-a842-4377-916f-ec2c53991282",
   "metadata": {},
   "outputs": [],
   "source": [
    "busted_merge = pandas.merge(\n",
    "    orders2,\n",
    "    products,\n",
    "    left_on=\"product_id\",\n",
    "    right_on=\"id\"\n",
    ")\n",
    "busted_merge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce11e9de-6cdd-4247-9ce7-1e25f2db0651",
   "metadata": {},
   "source": [
    "????\n",
    "Where did order 3 go??\n",
    "\n",
    "Ok. Ok. You got me. Inner merge is the same concept as an inner join, so the \"query\" (or merge in this case) is only going to include rows that have complete/perfect matches. \n",
    "\n",
    "Let's look at two different locations of \"Sully's Hahdware\" stores in the Greater Boston area. (Yes, I made it up)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fa97b7-6a98-408c-9dde-ee71d2eb0164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Billerica store\n",
    "billerica = pandas.read_csv('billerica.csv')\n",
    "billerica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f001a9cd-7b98-4136-9889-2b68cb518d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Methuen store\n",
    "methuen = pandas.read_csv('methuen.csv')\n",
    "methuen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7d7fc4-eb8b-440b-9dac-1675750ad793",
   "metadata": {},
   "source": [
    "As you can see there are a lot of columns without perfect matches, so an inner merge probably isn't going to work. Introducing\n",
    "\n",
    "### Outer Merges!\n",
    "\n",
    "An outer merge includes ALL rows from both tables even if they don't match. (remember?? We used this strategy w/ the Celtics!) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04918c9-ad30-4af3-bec3-2070fb77776f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas.merge(billerica, methuen, how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b592d6-6319-4eeb-888d-d3230b370de2",
   "metadata": {},
   "source": [
    "### Left and Right Merge\n",
    "\n",
    "As we saw above, imperfect matched rows result in NaNs or Nones. In the case above, it is a valid value, because we're measuring inventory across multiple stores. \n",
    "\n",
    "Let's look at left and right merge. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e40fb18-0667-410d-ac42-08a7a282f1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# left merge for Billerica\n",
    "## This is going to show the products that are in Billerica but not Methuen. \n",
    "## In other words we'll only include non-matching values from the \"right\".\n",
    "pandas.merge(billerica, methuen, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691ddd24-4a40-4e86-a972-58af27567ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets swap this as a left merge for methuen  (Same concept, just switching which column is on the left)\n",
    "pandas.merge(methuen, billerica, how='left') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241614da-a21a-434c-b8f1-8629bb74d515",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What about a right merge??\n",
    "## This will show the same result we had when performing a left merge on billerica, but we've reordered the columns. \n",
    "pandas.merge(methuen, billerica, how='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a321e3-e546-44c9-84a5-98dde072b478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# right merge on methuen to go full circle...\n",
    "pandas.merge(billerica, methuen, how='right')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31ee2ab-f00a-4cdf-9f60-a9a99b39666e",
   "metadata": {},
   "source": [
    "### Concatenation\n",
    "\n",
    "This is a wonderful tool. Concatenate allows you to add multiple dataframes together. This is very useful when you want to store large (**LARGE**) datasets in the cloud, but want to avoid massive download times. It's also useful in breaking up spreadsheets or csv files to avoid LFS limitations in git. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b74d284-e7f4-4c71-ba05-09b9607f570f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# go get our CSVs.\n",
    "black_lion = pandas.read_csv('black_lion.csv')\n",
    "red_lion = pandas.read_csv('red_lion.csv')\n",
    "blue_lion = pandas.read_csv('blue_lion.csv')\n",
    "green_lion = pandas.read_csv('green_lion.csv')\n",
    "yellow_lion = pandas.read_csv('yellow_lion.csv')\n",
    "\n",
    "voltron = pandas.concat([black_lion, red_lion,blue_lion,green_lion,yellow_lion]).reset_index()\n",
    "voltron"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
