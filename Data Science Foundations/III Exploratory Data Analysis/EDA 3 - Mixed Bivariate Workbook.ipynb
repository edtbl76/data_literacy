{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a9cd4fd-5481-473c-ab7d-186d1535bc57",
   "metadata": {},
   "source": [
    "# EDA 3 - Mixed Bivariate Analysis: Quantitative and Categorical\n",
    "\n",
    "\n",
    "### Inspection and Summarization\n",
    "\n",
    "We'll kick this off by setting up our environment and doing a preliminary investigation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d491f6-6174-4faf-a32c-932489f2b5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas and numpy. We can go ahead and use the aliases... \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "students = pd.read_csv('students.csv')\n",
    "\n",
    "students.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88b8f82-1e0c-4fdb-824f-714efd43513a",
   "metadata": {},
   "source": [
    "---\n",
    "We have 6 variables\n",
    "- **school**: This appears to be a nominal, categorical variable\n",
    "- **address**: This appears to be a categorical variable. Hard to tell from this what kind.\n",
    "- **absences**: This appears to be a discrete numerical variable. \n",
    "- **mom_job** and **dad_job**: These appear to be nominal categorical variables.\n",
    "- **math_assessment_score**: This appears to be a discrete numerical variable.\n",
    "\n",
    "Let's take a closer look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbeb0c1-95ee-4c75-bda5-659fffeb9476",
   "metadata": {},
   "outputs": [],
   "source": [
    "students.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b355328-8596-4040-89c1-98bf2b2621f1",
   "metadata": {},
   "source": [
    "---\n",
    "Pandas doesn't identify bools or strings when data is imported, so our initial analysis is confirmed by this output. \n",
    "\n",
    "We see that our data has a shape of 6 x 395 based on the non-null count and # of columns, but let's confirm that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdfbb2e-fefa-407c-8a43-dd6947dc05a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Columns: {len(students.columns)}, Observations: {len(students)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36a763e-09d9-40cc-8338-9b04ff7f1934",
   "metadata": {},
   "source": [
    "---\n",
    "Nice! So that was right too. Before we dig in to these values... let's make sure the non-null counts are accurate. Sometimes the data has values that *mean* null, but aren't evaluated that way. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47b4bd8-c1e1-4f45-9a74-d0b9bd5420e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a quick check for null shows that aren't any, but this is just a different representation of the same Non-Null Count column from info()!\n",
    "students.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7965822-7657-4776-849c-5f77b06cd74d",
   "metadata": {},
   "source": [
    "---\n",
    "Put a pin this. We'll come back to it. Let's take a closer look at each of the variables values to get a better idea of how much the variables actually vary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aeed8a4-1fa8-4b33-8037-e4e8232963cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# school\n",
    "students.school.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fcdd6b-0bfe-4f93-8c58-f2e8f5bf6dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# address\n",
    "students.address.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233285d4-f0c2-4b10-b03c-8a26f8d8e226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# absences\n",
    "students.absences.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130c16d6-acd8-4bce-b20e-e059ef091b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mom_job\n",
    "students.mom_job.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5609a6bc-7d27-4f98-b2ee-2b355b170aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dad_job\n",
    "students.dad_job.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32ff0b4-4103-4a95-9d6f-ce38f3dbecf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# math assessment score\n",
    "students.math_assessment_score.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648939a4-b8b9-4cb0-a1d0-9a6b0bbbce1f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Alright. We can see now that **school** and **address** are actually binary variables. Nothing appears ordinal, and we don't want to change school and address to bool, because we want the actual labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785c7a34-8848-4f3f-aa94-6b180b3c3f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "students.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983c2980-78b9-4acc-bc97-b88a9f167b4c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Hm. Remember when I said put a pin in the non-null counts? Let's take that pin out for a second. \n",
    "\n",
    "1. I see '0' in **absences** and **math_assessment_score.**\n",
    "\n",
    "For **absences**, it's not unthinkable that a student didn't miss any days of school, so 0 is likely a real count. \n",
    "For **math_assessment_score**, it's also not thinkable that someone got a 0 on the assessment. It's rare, but it does happen. \n",
    "\n",
    "Many folks think that null values are the \"worst thing we can find\". Null and NaN are wonderful, because they are explicit. It is the data equivalent of *I don't know*. From this point, we have to determine how we plan to handle null values. Do **NOT** create a one-size-fits-all approach. Handling null values is contextual. It depends on the data, and in many cases it also depends on the questions you are asking. \n",
    "- there are cases where a sufficient lack of observations in a column that is deemed irrelevant to the question at hand can be solved simply by dropping or ignoring the column. If I'm doing a study on the impact of eye color on night blindness, a lack of observations about gender or height are immaterial.\n",
    "- \"filling in\" data is another approach. This involves replacing null values with an appropriate substitute. Using 0 or a 'null' string aren't always appropriate. For normal distributions with considerable clustering around modal centers, it might make sense to use the median or mode. In other cases, for heavily sparse and scattered data, using an averaging algorithm and random selection can also be a useful substitute. Don't take this process lightly. Most data engineering/science boot camps hand wave over this step. \n",
    "- Last but not least...it's never a bad idea to see if the data exists somewhere else. A little detective work can go a long way. Sometimes a bad upload, or network instability during platform hydration can lead to missing values. \n",
    "\n",
    "2. I also see 75 **absences** as a max. That seems like an outlier or even incorrect. (The 0 in the **math_assessment_score** might also be incorrect or an outlier).\n",
    "\n",
    "You thought null values were bad! Outliers and incorrect data are far worse. The challenge is that in most cases, only the most absurd, extreme cases are we able to determine when a value is simply wrong. In those rare cases, we can treat them as a null value and resolve them. ```(while also being good citizens and notifying engineering teams or peers in our teams if that is the case, that we need to investigate why that data is garbage)```\n",
    "\n",
    "However, more often than not, these outliers are weird edge cases that were actually observed. Ideally, the outlier comes with an explanation of why, but... that is also usually not present. Handling outliers is a challenge, because removing them makes our analysis contrived in order to generate predictable patterns and results. It's often something we've come to accept in certain industries and domains, however it isn't something we can always ignore. Outliers in life-or-death situations might still cause death, so we end up having to spend more energy understanding why they exist. So... outliers are very contextual. \n",
    "\n",
    "For the sake of this exercise, I did give New Trier High School as one of the schools (From John Hughes' immortal film, [The Breakfast Club](https://www.imdb.com/title/tt0088847/). We'll pretend the 75 absences are Judd Nelson. \n",
    "\n",
    "We'll assume that all of the data is complete. \n",
    "``` NOTE: The EDA Diagnosing Diabetes Project included in this section DOES go through the process of replacing values and analyzing it if you'd like to take a closer look. ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6b8848-0a0f-4988-a2a6-b162b16e40ab",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# First associative investigation: Does address urban/rural associate w/ the math scores? \n",
    "\n",
    "Let's start by listing the scores from each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94b908e-48e6-4bf0-a9ab-b3c626c12c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Urban\n",
    "urban = students.math_assessment_score[students.address == 'U']\n",
    "len(urban)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f9c302-5ea4-4d54-a3ba-4c15868af599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rural\n",
    "rural = students.math_assessment_score[students.address == 'R']\n",
    "len(rural)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6fff9b-e6c1-467b-a0ff-060a8e6d1d9d",
   "metadata": {},
   "source": [
    "---\n",
    "At first glance, most of the values are urban. (Which makes sense). \n",
    "\n",
    "Before we start to hunt down the values... let's do a describe on each set to see the quick summaries. \n",
    "\n",
    "Remember that we'll only see a single variable represented, the numerical variable (**math_assessment_score**). The categorical variable was used to filter and create this subset of the data, so it's built-in to the ```urban/rural``` Series' we created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67592205-af3a-42ea-91ca-15e8f3342d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# urban\n",
    "urban.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06700b6c-1ea3-4373-b5e4-ce239e62a20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rural \n",
    "rural.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd11dc3-1bec-442c-93fe-78a0c7c91831",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Let's explicitly go get the mean and median for each of the subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4369504-f327-4510-9f08-cf2d423f7734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean calculations\n",
    "urban_assessment_mean = urban.mean()\n",
    "rural_assessment_mean = rural.mean()\n",
    "\n",
    "# Median Calculations\n",
    "urban_assessment_median = urban.median()\n",
    "rural_assessment_median = rural.median()\n",
    "\n",
    "print(f'Urban Students Scores (Mean): {urban_assessment_mean}')\n",
    "print(f'Rural Students Scores (Mean): {rural_assessment_mean}')\n",
    "print(f'Urban Students Scores (Median): {urban_assessment_median}')\n",
    "print(f'Rural Students Scores (Median): {rural_assessment_median}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9327a77-3baf-436b-933f-e87ff534abcd",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "```NOTE: Make note that the median is the same thing as the 50% quartile. This is why I keep saying that the IQR represents the spread of 25% of the data points to either side of the median!```\n",
    "\n",
    "What's the difference between the means and medians? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4f8d64-e58f-4762-9e23-6fcc27ff6ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean difference\n",
    "print(f'Mean   Difference (Urban - Rural): {urban_assessment_mean - rural_assessment_mean}')\n",
    "\n",
    "# median difference\n",
    "print(f'Median Difference (Urban - Rural): {urban_assessment_median - rural_assessment_median}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c2b9e0-4414-4048-8fcd-67d03b52a9d0",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "You probably notice that the two values are fairly similar. These are both measures of central tendency. \n",
    "\n",
    "Do you remember those outliers I mentioned? Removing outliers from datasets is something we try to avoid, because it no longer represents reality. (Even if the 'noise' being injected by reality is minute). \n",
    "\n",
    "The mean/average is influenced by outliers, because the process of averaging a set of values requires us to consider those values in the final outcome. However, the median is a positional concept. If I have any odd number of values, the median is always the observed value that exists at that middle position. (There are techniques for solving for the middle of an evenly-numbered set of data). \n",
    "\n",
    "The median is resilient in the presence of outliers, because it ignores the values. \n",
    "\n",
    "A common question is \"Why do we even bother studying statistics that aren't resilient to outliers?\". \n",
    "It's a good question. The reason, is that by analyzing the difference of resilient and non-resilient measures, we can understand the weight or pull of outliers on a data set. \n",
    "\n",
    "In fact, this is how we can determine potential skew without looking at the data set. (At the same time it helps explain why the 'skew' follows the tail and not the hump of the data distribution). \n",
    "\n",
    "Visualize a standard bell curve. We call this a normal distribution because it's symmetrical and equivalent. If there is a long tail to the right, it has the affect of making the hump appear to \"fall to the left\". However, we refer to this as \"right skewed\". Visually this isn't intuitive. However, when you think of the data, and the examples above, it means that the outliers or the continuance of data observation is what trends to the right. Those outliers \"pull\" on the data, and we observe this in analysis. \n",
    "\n",
    "```\n",
    "When a mean is > than the median, it generally means that the data is skewed to the right or with increasing values. \n",
    "When a mean is < than the median, it generally means that the data is skewed to the left or with decreasing values.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2136e314-fea8-4967-8421-1aaafb5b7ecb",
   "metadata": {},
   "source": [
    "### Let's Visualize the Data!!!\n",
    "\n",
    "Let's take a look at parallel boxplots to visualize the difference in the data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3508faa-3143-425f-b40c-6c994e1e64af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup!\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb182380-e2db-496c-bbe8-8e068eb86b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actually create the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173d41ef-50d0-469e-9b5e-f918708bd718",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=students, x='address', y='math_assessment_score')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deaeea49-b9fc-4964-8f5d-b4777513847f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Do you remember our original question? (That's ok me either!) \n",
    "\n",
    "We wanted to know if there is an association between address (urban or rural) and the outcomes of the math_assessement test the students participated in. \n",
    "\n",
    "What do you think? \n",
    "\n",
    "#### Box and Whiskers\n",
    "Let's start by describing how a boxplot measures data. \n",
    "\n",
    "Some people refer to this as **box and whiskers**, where the whiskers are the lines or arms extending from the colored box. \n",
    "- The line in the middle of the box is the **median** or 50% quartile.\n",
    "- The box itself represents the **(IQR) interquartile range**.\n",
    "- The lower edge (top-bottom) or left edge (left-right) is the 25% quartile.\n",
    "- The upper edge (top-bottom) or right edge (left-right) is the 75% quartile.\n",
    "- The lines at the edge of the whiskers are the minimum and maximum values (This is going to be confusing in a second...).\n",
    "- Any diamonds or dots outside the whiskers are outliers.\n",
    "\n",
    "\n",
    "##### Tangent\n",
    "You're probably wondering how the outliers are identified.\n",
    "\n",
    "Mathematically the common formula for this is: \n",
    "- **lower**: Values less than Q1 - 1.5 X IQR\n",
    "- **upper**: Values greater than Q3 + 1.5 X IQR.\n",
    "\n",
    "We can test this. \n",
    "\n",
    "If you revisit our ```describe()``` call above on the **urban** set. \n",
    "\n",
    "```\n",
    "count    307.000000\n",
    "mean      10.674267\n",
    "std        4.563075\n",
    "min        0.000000\n",
    "25%        9.000000\n",
    "50%       11.000000\n",
    "75%       14.000000\n",
    "max       20.000000\n",
    "```\n",
    "\n",
    "We see that the minimum value is 0, but our boxplot disagrees. It shows something that appears to be ~4. The 0 is an outlier. \n",
    "\n",
    "Let's calculate the lower bound mentioned above. \n",
    "Q1 = 25% = 9\n",
    "The IQR = Q3 - Q1 = 14 -9 = 5\n",
    "\n",
    "So the equation is: 9 - 1.5 x 5 = **1.5**\n",
    "\n",
    "The 0 falls outside of that range, so it is plotted by ```matplotlib``` and ```seaborn``` as an outlier. The actual values more than likely don't go below whatever the value is that is reflected by the end of the whisker. \n",
    "\n",
    "##### End Tangent\n",
    "\n",
    "Now that we understand the box and whiskers plot... what do you see? \n",
    "\n",
    "- the medians are almost the same.\n",
    "- the IQRs have about 50% overlap, maybe more.\n",
    "- The upper whiskers are almost even\n",
    "- The lower whiskers are a little bit more interesting. The 0 in rural falls into the range of the IQR, whereas it's an outlier in urban, which suggests that there were a greater number of rural students who did poorly.\n",
    "\n",
    "This tells us that, overall, the students appeared to do mostly the same on the assessment regardless of where they lived. Our analysis would lead us to believe that there is little to no association between address and score. \n",
    "\n",
    "```\n",
    "This tells you (the learner) that:\n",
    "\n",
    "- similar results mean less association.\n",
    "- different results mean more association or correlation.\n",
    "\n",
    "Showing a change tied to variables is what we want to see in most cases. If Y remains the same in response to a different X... we don't learn as much as we do when Y changes too. \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c7499e-9d58-4234-9d17-2faab8d27ca8",
   "metadata": {},
   "source": [
    "#### Overlapping Histograms. \n",
    "\n",
    "This is just a different visualization for looking for associations. Same data, different picture. \n",
    "\n",
    "The trick to overlapping histograms is transparency. Like literal visual transparency otherwise we can't see through the top histogram to the bottom one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02699713-04b2-4fbb-9364-e7b8f95503a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpha is the variable to set transparency. 50% is a good baseline. \n",
    "# density used to be called 'normed'. This normalizes the values to be displayed as a probability density rather than frequency. \n",
    "plt.hist(urban, color='green', label='Urban Scores',alpha=0.5, density=True)\n",
    "plt.hist(rural, color='blue', label='Rural Scores', alpha=0.5, density=True)\n",
    "\n",
    "# useful if you want people to know what they are looking at. \n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e44921-8f7e-4d75-9510-643a266dbb30",
   "metadata": {},
   "source": [
    "One of the reasons I like this is that it gives us a better indication of frequency or proportion. You can see that there is a gap between the observed 0 in both distributions, which suggests that it could potentially be an outlier in either case (semantically) despite the fact that it wasn't categorized as one for the rural distribution (formulaically) \n",
    "\n",
    "Why did I use the ```density=True``` flag to convert the visualization into proporitions rather than the default frequencies? \n",
    "\n",
    "Numerically, it wasn't apples to apples. We had only 88 observations from rural students but 307 from urban students. In some cases, the disparity is even larger. \n",
    "\n",
    "```ratios are better for comparison than actual values```\n",
    "\n",
    "See for yourself..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5cd812-8aa9-430b-bbac-146a0105f795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# same viz w/o normalization\n",
    "plt.hist(urban, color='green', label='Urban Scores',alpha=0.5)\n",
    "plt.hist(rural, color='blue', label='Rural Scores', alpha=0.5)\n",
    "\n",
    "# useful if you want people to know what they are looking at. \n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf5253f-5c96-4ed1-b8bf-b48eff733378",
   "metadata": {},
   "source": [
    "### One last peek... what if our categorical variable wasn't binary??\n",
    "\n",
    "In many cases, we aren't trying to compare between two known groups or clusters. Sometimes we're analyzing a feature or variable to look for patterns or associations to try to solve a problem or better understand the problem space itself. \n",
    "\n",
    "What if we compared the scores to mom and dad's jobs? \n",
    "\n",
    "```\n",
    "It hopefully goes without saying that this is much easier to do w/ boxplots than overlapping histograms... although there are some cool 3d tools out there that make the latter possible although not any more viable. \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7caef0c-f895-4a50-a9c0-e14b75bf668c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mom\n",
    "sns.boxplot(data=students, x='mom_job',y='math_assessment_score')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b629b1-ed41-4302-a32d-a99e9a51b1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dad\n",
    "sns.boxplot(data=students, x='dad_job',y='math_assessment_score')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9dda514-de9e-4094-b29b-0e6f6b5d08b6",
   "metadata": {},
   "source": [
    "As you can see.. it doesn't appear there is much association here. We can certainly see some trends (i.e. dad teachers IQR is much higher). \n",
    "\n",
    "Intuitively this makes sense. Think about the data and the reality of the situations for a moment. Just because mom or dad are teachers doesn't mean they are helping their kids with their homework. We don't have a variable for that. We would need to correlate job to "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
